---
title: "Phase 2 - Data description"
format: html
editor: 
  markdown: 
    wrap: sentence
---

## Libraries

```{r}
#| echo: false
#| message: false
#| warning: false
library(vroom)
library(here)
library(tidyr)
library(dplyr)
library(knitr)
library(kableExtra)
library(readr)
library(ggplot2)
library(httr2)
```


## Adding the data

```{r}
#| echo: false
#| message: false
emissions_data <- vroom(here("data", "emissions_by_unit_and_fuel_type_c_d_aa.csv"))
workforce_ca_data <- vroom(here("data", "qwi_ca_se_f_gs_n4_oslp_u.csv"))
workforce_tx_data <- vroom(here("data", "qwi_tx_se_f_gs_n4_oslp_u.csv"))
subsectors_type <- vroom(here("data", "subsect_types.csv"))
```


## Links and sources


### Link to the github project

You can find our github repository here : [Research Project](https://github.com/vito100-8/Research_project.git).

Due to our use of very large data files, we used Git LFS (Large File Storage) that allowed us to push our data into the project repository.


### Some infos about the data sources

We used two data sources : the US Environmental Protection Agency and the US Census Bureau.


#### Environmental Protection Agency

The Environmental Protection Agency (EPA) is an American federal agency which takes part in scientific research and enforces environmental laws by developing regulations to contribute to the preservation of the environment.
Its main missions are fighting against climate change, reducing pollution, and ensuring environmental equity.
As part of its monitoring and regulatory role, the EPA produces multiple databases, such as the Air Quality System (AQS, which contains data from air pollution monitoring stations across the U.S; Greenhouse Gas (GHG) Reporting Program which provides data on greenhouse gas emissions from large facilities.
The dataset which we will use in this project is part of the GHG Program.
All datasets of the EPA are open data, as part of the objective of scientific transparency which is promoted by the agency.
The EPA also possesses its own built-in data tools, like EnviroFacts, which allows for an immediate analysis of data.


#### United States Census Bureau

The U.S. Census Bureau, part of the Department of Commerce, is the federal agency responsible for collecting and analyzing data about the U.S. population and economy.
Its primary role is conducting the decennial U.S.
Census, which determines congressional representation, legislative district boundaries, and the allocation of federal funds for infrastructure, healthcare, etc.
The agency also conducts the Economic Census every five years, which provides data on the industries and businesses in the US.
The agency also conducts yearly, quarterly and monthly surveys about the socio-economic dynamics of the population and labor statistics.
The dataset we used is part of the Quarterly Workforce Indicators,coming from the Longitudinal Employer-Household Dynamics page.
The QWI is particular in the way that it is able to link workers to where they work, which allows for the identification of worker flows, demographics etc.
The US Census Bureauâ€™s data is accessible and open to all.
Through the platform data.census.gov, one is able to add and filter data directly for analysis or creation of geographic maps, tables etc.


### Links to the dataset sources

Emissions by Unit and Fuel Type : [US Environmental Protection Agency](https://www.epa.gov/ghgreporting/data-sets).

To download the dataset : [Emissions Zip File](https://www.epa.gov/system/files/other-files/2024-10/emissions_by_unit_and_fuel_type_c_d_aa.zip).

The zipped file contained an Excel binary file, with four sheets : Emissions by Unit type, Emissions by Fuel type, Industry type referencing to the first two sheets and a Q&A sheet.
We chose to focus on only the first sheet, which contained CO2 emissions of energy producers.
The third sheet containing information about the sub-sectors in which the energy facilities are listed.
We saved these two sheets in two separate CSV files.
We needed to unzip it and create a CSV manually because the native file contained lines not understandable by R.

Quarterly Workforce Indicators (QWI) Data : [US Census Bureau](https://lehd.ces.census.gov/data/#qwi).

For the State of California :[California_WF](https://lehd.ces.census.gov/data/qwi/latest_release/al/qwi_ca_se_f_gs_n4_oslp_u.csv.gz).

For the State of Texas : [Texas_WF](https://lehd.ces.census.gov/data/qwi/latest_release/al/qwi_tx_se_f_gs_n4_oslp_u.csv.gz).

We manually unzipped these two datafiles before loading it into R. 


## About the datasets

```{r}
#| echo: false
# Summary table for emissions
emissions_summary <- emissions_data |>
  summarise(
    "Number of rows" = nrow(emissions_data),
    "Number of columns" = ncol(emissions_data),
    "Period" = paste(range(`Reporting Year`), collapse= " - "),
    "Periodicity" = "Annual",
    "Extremum levels of CO2 emissions " = paste(range(`Unit CO2 emissions (non-biogenic)`), collapse = " - "),
    ### separate the rows that have a "," to not double count firms in several subsectors as distinct values
    "Number of sectors" = n_distinct(unlist(strsplit(paste(`Industry Type (sectors)`, collapse = ","), ",\\s*"))), 
    "Number of subparts" = n_distinct(unlist(strsplit(paste(`Industry Type (subparts)`, collapse = ","), ",\\s*"))),
    "Number of different companies" = length(unique(`Primary NAICS Code`)),
    "Total number of missing values across the sheet" = sum(sapply(emissions_data, function(x) sum(is.na(x))))
  )

emissions_summary |>
  kable("html", caption = "Emissions database information") |>
  kable_styling(full_width = T, bootstrap_options = c("striped", "hover", "condensed"))
```

```{r}
#| echo: false
# Summary table for workforce

## workforce summary for California
workforce_ca_summary <- workforce_ca_data |>
  summarise(
    "State" = "California",
    "Number of rows" = nrow(workforce_ca_data),
    "Number of columns" = ncol(workforce_ca_data),
    "Period" = paste(range(year), collapse= " - "),
    "Periodicity" = "Quarterly",
    "Extremums of employment (Quarterly)" = paste(range(EmpTotal, na.rm = TRUE), collapse= " - "),
    "Number of industry (NAICS 4)" = length(unique(industry)),
    "Total number of missing values across the sheet" = sum(sapply(workforce_ca_data, function(x) sum(is.na(x))))
  )

## workforce summary for Texas
workforce_tx_summary <- workforce_tx_data |>
  summarise(
    "State" = "Texas",
    "Number of rows" = nrow(workforce_tx_data),
    "Number of columns" = ncol(workforce_tx_data),
    "Period" = paste(range(year), collapse= " - "),
    "Periodicity" = "Quarterly",
    "Extremums of employment (Quarterly)" = paste(range(EmpTotal, na.rm = TRUE), collapse= " - "),
    "Number of industry (NAICS 4)" = length(unique(industry)),
    "Total number of missing values across the sheet" = sum(sapply(workforce_tx_data, function(x) sum(is.na(x))))
  )

## Table of each summary
workforce_summary <- bind_rows(workforce_ca_summary, workforce_tx_summary)


workforce_summary |>
  kable("html", caption = "Workforce database information") |>
  kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
```

```{r}
#| echo: false
# Join California and Texas and summary of this join
## Joining the two datasets

### Giving geography the same class for both in order to bind rows (it was double for Texas and character for California previously)
workforce_tx_data <- workforce_tx_data |>
  mutate(geography = as.character(geography))


workforce_ca_tx <- bind_rows(
  workforce_ca_data |> mutate(Region = "California"),
  workforce_tx_data |> mutate(Region = "Texas"))

## Summarizing the combined dataset
workforce_ca_tx_summary <- workforce_ca_tx |>
  summarise(
    "Region" = "California, Texas",
    `Number of rows` = nrow(workforce_ca_tx),
    `Number of columns` = ncol(workforce_ca_tx),
    Period = paste(range(year), collapse= " - "),
    Periodicity = "Quarterly",
    `Extremums of employment (Quarterly)` = paste(range(EmpTotal, na.rm = TRUE), collapse= " - "),
    `Number of industry (NAICS 4)` = length(unique(industry)),
    `Total number of missing values across the sheet` = sum(sapply(workforce_ca_tx, function(x) sum(is.na(x))))
  )

## Displaying the combined summary
workforce_ca_tx_summary |>
  kable("html", caption = "Combined Workforce Database Information") |>
  kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
```


## Description of key variables


### Emissions dataset

`Primary NAICS Code` : this variable identifies each firm and will allow us to merge the two datasets by agregating each firm into a NAICS code 4 (at the level of industries).
`Unit CO2 emissions (non-biogenic)`: gives the quantity of CO2 emissions for each unit (described by the variables `Unit Name` and `Unit Type`) of each firm for a given year


### Workforce datasets

`industry`: NAICS 4 code that identifies the industries
`geography`: geography code that identifies the state
`EmpTotal`: the variable counts the estimated number of people employed in a firm at any time during the quarter according to the subsector, age and sex categories (we will agregate those specifications later on)
`EarnS` : gives us the average monthly earnings of employees with stable jobs (in dollars)


## Data treatment


### Merge preparation for the workforce dataset (California and Texas)

To match with the more restricted time period covered by the `emissions_data` dataset, we started by reducing the time period covered by the `workforce_ca_data` and the `workforce_tx_data`datasets to be between 2011 and 2023. 

The `industry` variable in the `emissions_data` dataset contains NAICS4 level industry codes. We therefore filtered the two workforce datasets to show only the observations when `ind_level` was equal to 4 (which corresponds to NAICS 4). 

We then selected the key variables from both workforce datasets according to our research question. We decided to keep the `sex` and `education` variables in case we would need them for future analysis ex. checking for endogeneity (as instrument variables).

Finally, as to match the annual data contained in the `emissions_data` dataset, we replaced the values of our interest variables, which were quarterly counts/rates, with average annual data by taking the mean of their quarterly values. 
The new average annual variables are ; `avg_Emp` for the average annual Employment Count, `avg_FrmJbC` for the average annual Firm Job net Change (Hire-Separation), and `avg_EarnS` for the annual average wage (paid for a month).

```{r}
#| message: false

## for the California workforce dataset
clean_wf_ca_data <-
  workforce_ca_data |>
  ### selection of analysis period and sector-level
  filter(year > 2010 & year < 2024) |>
  filter(ind_level == 4) |>
  ### selection of variables of interest
  select(industry, sex, education, year, quarter,geography, EmpTotal, EarnS, FrmJbC) |>
  ### replacing quarterly data with annual data by taking the mean value of the four quarters in a year
  group_by(industry, sex, education, year, geography) |>
  summarise(
    avg_Emp = round(mean(EmpTotal, na.rm = TRUE)),
    avg_FrmJbC = round(mean(FrmJbC, na.rm = TRUE)),
    avg_EarnS = mean(EarnS, na.rm = TRUE)
  )

## for the Texas workforce dataset
clean_wf_tx_data <-
  workforce_tx_data |>
  ### selection of analysis period and sector-level
  filter(year > 2010 & year < 2024) |>
  filter(ind_level == 4) |>
  ### selection of variables of interest
  select(industry, sex, education, year, quarter, geography, EmpTotal, EarnS, FrmJbC) |>
  ### replacing quarterly data with annual data by taking the mean value of the four quarters in a year
  group_by(industry, sex, education, year, geography) |>
  summarise(
    avg_Emp = round(mean(EmpTotal, na.rm = TRUE)),
    avg_FrmJbC = round(mean(FrmJbC, na.rm = TRUE)),
    avg_EarnS = mean(EarnS, na.rm = TRUE)
  )
```


### Merge preparation for the emissions dataset

```{r}
#| message: false

## filtering the initial data
emissions_data <- emissions_data |>
  ### keeping only data from 2011 - 2023 
  filter(`Reporting Year` > 2010)


emissions_data <- emissions_data |>
  ### keeping only the relevant columns
  select(State:`Unit Type`, `Unit CO2 emissions (non-biogenic)`:`Unit Biogenic CO2 emissions (metric tons)`)

## aggregating the database into a subsectors (NAICS 4) level
clean_em_data <- emissions_data |> 
  ### We only keep Californian and Texas firms
  filter(State == "CA" | State == "TX") |>  
  mutate(
    ### aggregation at NAICS 4 level
    `NAICS 4 (subsectors)` = substr(`Primary NAICS Code`, 1, 4), 
    ### to avoid issues with the missing values during the sum after with parse number (convert from character to numerical)
    `Unit CO2 emissions (non-biogenic)` = parse_number(`Unit CO2 emissions (non-biogenic)`),  
    `Unit Methane (CH4) emissions` = parse_number(`Unit Methane (CH4) emissions`),
    `Unit Nitrous Oxide (N2O) emissions` = parse_number(`Unit Nitrous Oxide (N2O) emissions`),
  ) |> 
  ### group by NAICS subsectors i.e. industries, reporting year and unit type
  group_by(`NAICS 4 (subsectors)`, `Reporting Year`, State) |> 
  summarise(
    ### we keep our values of interest
    `Total CO2 Emissions (non_biogenic)` = sum(`Unit CO2 emissions (non-biogenic)`, na.rm = TRUE), 
    `Total CH4 Emissions` = sum(`Unit Methane (CH4) emissions`, na.rm = TRUE),
    `Total N20 Emissions` = sum(`Unit Nitrous Oxide (N2O) emissions`, na.rm = TRUE),
    `Total Biogenic C02 emissions` = sum(`Unit Biogenic CO2 emissions (metric tons)`, na.rm = TRUE ),
    `Number of firms` = n()
  )

## changing variable names to have them similar across the two datasets
clean_em_data <- clean_em_data |>
  rename(year = `Reporting Year`)
clean_em_data <- clean_em_data |> 
  rename(industry = `NAICS 4 (subsectors)`)
```


### Merging datasets

After we cleaned up the datasets, we first merged the `clean_wf_tx_data` and the `clean_wf_ca_data` datasets together to be stacked one under the other. This way, the observations from the two datasets can only be differenciated by the `geography column`, which contains the geopgraphy code correspondonding to the two chosen States. 

To be able to execute the second merge with the `clean_em_data` dataset, we also renamed `geography` to `State` and changed the observations, which were geography codes, to the abbreviation of the state name, as it figures in the `clean_em_data` dataset.

Finally, we did a `left_join()` merge of the two final datasets. As the workforce datasets contained observations for all industry sectors, while the `Ã¨missions_data` dataset only contained observations for energy producing sectors, we did a final filtering to drop the missing values corresponding to non-energy producing sectors. 

```{r}
# Combining the two workforces datasets

## bind rows to have in a single dataset both state workforce data (identified by the geography variable)
join_wf_data <- bind_rows(clean_wf_tx_data, clean_wf_ca_data)

## rename geography into a state variable as in the emission dataset to be able to merge with this variable as well
join_wf_data <- join_wf_data |> 
  mutate(State = if_else(geography == "48", "TX", "CA") ) |>
  select(!geography)
```

```{r}
#| message: false
# Merging emissions and workforce datasets using workforce data as master, so we can keep all observations from the latter dataset
joined_dataset <- left_join( join_wf_data, clean_em_data)

# Cleaning for the missing values of emissions
joined_dataset <- joined_dataset |> filter(is.na(`Total CO2 Emissions (non_biogenic)`) == FALSE)

```

We now have our joined database combined of the previous `emissions_data`, `workforce_ca_data` and `workforce_tx_data` datasets.


## Main target variable

Our variable of interest is `CO2 emissions (non biogenic)`. To better analyze its relationship with the other variables we will use, we first need to represent its distribution and its characteristics. 

We constructed two charts :  
  - the first chart describes the evolution over time of `CO2 emissions (non biogenic)` for each `State`. We added a `NAICS2  (sectors)` variable to compute the absolute contribution of each sector(NAICS 2) for each state in a given year.
  - the second chart explores the relative contribution of each `State` in the total `CO2 emissions (non biogenic)` over the years.

```{r}
#| echo: false
#| message: false
# Evolution of Total CO2 Emissions of energy producers by State
joined_dataset |>
  mutate(
    `NAICS2  (sectors)` = substr(industry, 1, 2 ), .keep = "all") |>
  ggplot(aes(x = year, y = `Total CO2 Emissions (non_biogenic)`, fill = `NAICS2  (sectors)`)) +
  geom_col() +
  facet_wrap(vars(State), scales = "free_y")

# Same scale comparison : Texas vs California participation in C02 emissions
joined_dataset |>
  ggplot(aes(x = year, y = `Total CO2 Emissions (non_biogenic)`, fill = State)) +
  geom_col(position = "fill")
```


## Research question

We will be investigating the relationship between workforce characteristics (employment count, wage...) and CO2 emissions in energy-producing firms in California and Texas from 2011 to 2023.

We choose this time period because our emission dataset covers years from 2010 to 2023 but the first year had sparse data. Thus we decided to delete the year, which should not induce any major changes in further analyses.

For this study, we plan on conducting a panel analysis to have more information and to study the evolution in behavior of each industries over time. It will allow us to analyse the heterogeneity of responses of these industries (i.e. if some of them are more responsive to tax on their emissions than others). 

We firstly chose California as a huge polluting state (second most important emitter of C02) making efforts to transition towards clean energies as it introduced a cap-and-trade program in 2015 to regulate emissions . On the contrary, Texas is the leading energy supplier in the U.S. that still relies in majority on fossil fuels (most important emitter of C02). Studying these two states together allows for understanding  the role of workforce characteristics in shaping CO2 emissions under different regulatory environments. 

In other words, we chose the two states that are the biggest emitters to compare the underlying workforce factors that influence these emissions, Texas and California having different policies and regulations regarding those emissions.

There is literature highlighting the effect of average number of hours worked on carbon emissions with model including the population/industry size as a factor (see for example [Fitzgerald, 2022](https://doi.org/10.1016/j.erss.2021.102385) ). We decided to keep the size aspect with `avg_Emp` (that proxies the size of an industry by counting the number of employees working) but to analyze the effect of the average annual wage on those carbon emissions. 

We chose to use this variable as a proxy for workforce skill level and investment in human capital. The idea behind this is that "greener jobs" (so here represented by jobs associated with firms emitting relatively low levels of C02) tends to hire more skilled workers (see [Bowen et al., 2018](https://www.sciencedirect.com/science/article/pii/S0140988318300963), [Elliott and Lindley (2017)](https://www.sciencedirect.com/science/article/abs/pii/S0921800916311442)) with higher wages associated. Hence the analysis of the relationship between wages and carbon emissions

The aim here is also to check if that relationship is also true in energy producing industries, where greener jobs are associated with better production technologies and the type of energy produced.

Other key variable is Net employment change (`avg_FrmJbC`) which will be used as a proxy for contraction or expansion of firms in an industry. The hypothesis is that industries with quick expansions may emit more due to production scale (and inverse effect for industries shrinking).

We will also create dummies to separate our analysis in groups : 
- `State`will be divided in two (California and Texas)
- A policy dummy will be added to study the impact of new regulation aimed at reducing emissions, we will study the heterogeneity of response depending on the industry
- Separate industries according to whether it produces renewable energy or not.

Finally, controle variables will be implemented to capture unwanted effect such as `year` (erasing the special effect of being in a given year). 

The formal construction of our model will be described in the next phase.




